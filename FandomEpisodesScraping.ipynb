{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.13\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from warnings import warn\n",
    "\n",
    "import souphelper \n",
    "from souphelper import *\n",
    "\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Episodes Scraping from Fandom \n",
    "\n",
    "We want scraping from Fandom site all the simpsons episodes with: \n",
    "\n",
    "* Number total [Integer]\n",
    "* Number in season [Integer]\n",
    "* Season number [Integer]\n",
    "* Title [String]\n",
    "* Air date [Date with no time]\n",
    "* Production code [string]\n",
    "* Main characters [list of strings]\n",
    "* Written by [String]\n",
    "* Directed by [String]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://simpsons.fandom.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_SEPARATOR = \",\"\n",
    "\n",
    "def title(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        titleTag = episodeInfobox.find(\"h2\")\n",
    "        if titleTag:\n",
    "            return str(titleTag.string).strip()\n",
    "    return None\n",
    "\n",
    "def image(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        imageTag = episodeInfobox.figure\n",
    "        if imageTag:\n",
    "            return imageTag.a.img[\"src\"]\n",
    "    return None\n",
    "\n",
    "def episode_number(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        episodeNumberTag = episodeInfobox.find(attrs={\"data-source\": \"Episode Number\"})\n",
    "        if episodeNumberTag:\n",
    "            return str(episodeNumberTag.div.string).strip()\n",
    "    return None\n",
    "\n",
    "def production_code(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        production_codeTag = episodeInfobox.find(attrs={\"data-source\": \"productionCode\"})\n",
    "        if production_codeTag:\n",
    "            return str(production_codeTag.div.string).strip()\n",
    "    return None\n",
    "\n",
    "def airdate(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        airdateTag = episodeInfobox.find(attrs={\"data-source\": \"originalAirdate\"})\n",
    "        if airdateTag:\n",
    "            return str(airdateTag.div.string).strip()\n",
    "    return None\n",
    "\n",
    "def maincharacters(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        mainCharactersTag = episodeInfobox.find(attrs={\"data-source\": \"main_character(s)\"})\n",
    "        if mainCharactersTag:\n",
    "            mainCharactersContent = mainCharactersTag.div\n",
    "            handleP(mainCharactersContent)\n",
    "            handleLinebreaks(mainCharactersContent, STR_SEPARATOR)\n",
    "            return str(mainCharactersContent.string).strip()\n",
    "    return None\n",
    "\n",
    "def writtenby(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        writtenbyTag = episodeInfobox.find(attrs={\"data-source\": \"Written By\"})\n",
    "        if writtenbyTag:\n",
    "            writtenbyContent = writtenbyTag.div\n",
    "            handleP(writtenbyContent)\n",
    "            handleLinebreaks(writtenbyContent, STR_SEPARATOR)\n",
    "            return str(writtenbyTag.div.string).strip()\n",
    "    return None\n",
    "\n",
    "def directedby(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        directedbyTag = episodeInfobox.find(attrs={\"data-source\": \"Directed By\"})\n",
    "        if directedbyTag:\n",
    "            return str(directedbyTag.div.string).strip()\n",
    "    return None\n",
    "\n",
    "def episodeAttrs(episodePage:bs, **moreAttributes):\n",
    "    infobox = episodePage.find(class_=\"portable-infobox\")\n",
    "    return {\n",
    "        **moreAttributes,\n",
    "        \"title\": episodePage.find(id=\"firstHeading\").string.strip(),\n",
    "        \"image\": image(infobox),\n",
    "        \"episode number\": episode_number(infobox),\n",
    "        \"production code\": production_code(infobox),\n",
    "        \"airdate\": airdate(infobox),\n",
    "        \"main character(s)\": maincharacters(infobox),\n",
    "        \"written by\": writtenby(infobox),\n",
    "        \"directed by\": directedby(infobox)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esepisodesPage(page:bs):\n",
    "    return page.find(id=\"firstHeading\").string.strip() == \"List of Episodes\"\n",
    "\n",
    "def episodesURLs(episodesPage:bs):\n",
    "    if not esepisodesPage(episodesPage):\n",
    "        raise ValueError(\"Soup received is not a episodes page\")\n",
    "    \n",
    "    episodesSection = episodesPage.find_all(class_=\"oLeft\")[0]\n",
    "    episodes = episodesSection.find_all(class_=\"oLeft\")\n",
    "\n",
    "    links = []\n",
    "\n",
    "    for episode in episodes:\n",
    "        links.append(BASE_URL + episode.a[\"href\"])\n",
    "    return links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing single episode https://simpsons.fandom.com/wiki/Homer%27s_Odyssey\n",
      "{'url': 'https://simpsons.fandom.com/wiki/Homer%27s_Odyssey',\n",
      " 'title': \"Homer's Odyssey\",\n",
      " 'image': 'https://static.wikia.nocookie.net/simpsons/images/e/ed/Homer%27s_Odyssey_%28Mr._Burns_Looking_Out_the_Window%29.png/revision/latest/scale-to-width-down/350?cb=20200915011051',\n",
      " 'episode number': '3',\n",
      " 'production code': '7G03',\n",
      " 'airdate': 'January 21, 1990',\n",
      " 'main character(s)': 'None',\n",
      " 'written by': 'None',\n",
      " 'directed by': 'Wes Archer'}\n"
     ]
    }
   ],
   "source": [
    "EPISODE_PAGE = \"https://simpsons.fandom.com/wiki/List_of_Episodes\"\n",
    "\n",
    "TEST = True # scrape some random episodes\n",
    "EPISODE_TEST_URL = \"https://simpsons.fandom.com/wiki/Homer%27s_Odyssey\" # scrape only this if not None\n",
    "\n",
    "def scrapeEpisode(url:str):\n",
    "    episodePage = soup(url)\n",
    "    episode = episodeAttrs(episodePage, url=url)\n",
    "    return episode\n",
    "\n",
    "\n",
    "def scrapeEpisodes(EpisodePage = EPISODE_PAGE):\n",
    "    episodes = []\n",
    "    \n",
    "    episode = scrapeEpisode(EpisodePage)\n",
    "    pprint(episode, sort_dicts=False)\n",
    "    episodes.append(episode)\n",
    "\n",
    "    return episodes\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if EPISODE_TEST_URL:\n",
    "        print(\"Testing single episode \" + EPISODE_TEST_URL)\n",
    "        pprint(scrapeEpisode(EPISODE_TEST_URL), sort_dicts=False)\n",
    "    else:\n",
    "        if TEST:\n",
    "            scrapeEpisodes()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18b0eca292df7790ae02c99d513840323a4ed6febc80d490ebe22b975c5e1f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
