{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from warnings import warn\n",
    "\n",
    "import souphelper \n",
    "from souphelper import *\n",
    "\n",
    "import episodesEx \n",
    "from episodesEx import *\n",
    "\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Episodes Scraping from Fandom \n",
    "\n",
    "We want scraping from Fandom site all the simpsons episodes with: \n",
    "\n",
    "* URL episode [string]\n",
    "* Number total [Integer]\n",
    "* Season number [Integer]\n",
    "* Title [String]\n",
    "* Air date [Date with no time]\n",
    "* Production code [string]\n",
    "* Main characters [list of strings]\n",
    "* Written by [String]\n",
    "* Directed by [String]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://simpsons.fandom.com\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a series of functions for the attributes, to which we are interested, of the episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR_SEPARATOR = \",\"\n",
    "\n",
    "def title(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        titleTag = episodeInfobox.find(\"h2\")\n",
    "        if titleTag:\n",
    "            return str(titleTag.string).strip()\n",
    "    return None\n",
    "\n",
    "def image(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        imageTag = episodeInfobox.figure\n",
    "        if imageTag:\n",
    "            return imageTag.a.img[\"src\"]\n",
    "    return None\n",
    "\n",
    "def episode_number(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        episodeNumberTag = episodeInfobox.find(attrs={\"data-source\": \"Episode Number\"})\n",
    "        if episodeNumberTag:\n",
    "            return str(episodeNumberTag.div.string).strip()\n",
    "    return None\n",
    "\n",
    "def season(episodePage):\n",
    "    if episodePage:\n",
    "        number_season = episodePage.find(attrs={\"data-tracking-label\": \"categories-top-more-0\"}).string.strip()\n",
    "        res = [int(i) for i in number_season.split() if i.isdigit()]\n",
    "        if len(res) == 1:\n",
    "            return res[0]\n",
    "        elif len(res) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            warn(\"More than one season number forund\" + str(res))\n",
    "            return res[0]\n",
    "        return res\n",
    "    return None\n",
    "\n",
    "def production_code(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        production_codeTag = episodeInfobox.find(attrs={\"data-source\": \"productionCode\"})\n",
    "        if production_codeTag:\n",
    "            return str(production_codeTag.div.string).strip()\n",
    "    return None\n",
    "\n",
    "def airdate(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        airdateTag = episodeInfobox.find(attrs={\"data-source\": \"originalAirdate\"})\n",
    "        if airdateTag:\n",
    "            return str(airdateTag.div.string).strip()\n",
    "    return None\n",
    "\n",
    "def maincharacters(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        mainCharactersTag = episodeInfobox.find(attrs={\"data-source\": \"main_character(s)\"})\n",
    "        if mainCharactersTag:\n",
    "            mainCharactersContent = mainCharactersTag.div\n",
    "            handleP(mainCharactersContent)\n",
    "            handleLinks(mainCharactersContent)\n",
    "            handleLinebreaks(mainCharactersContent, STR_SEPARATOR)\n",
    "            return str(mainCharactersContent.string).strip()\n",
    "    return None\n",
    "\n",
    "def writtenby(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        writtenbyTag = episodeInfobox.find(attrs={\"data-source\": \"Written By\"})\n",
    "        if writtenbyTag:\n",
    "            writtenbyContent = writtenbyTag.div\n",
    "            handleP(writtenbyContent)\n",
    "            handleLinks(writtenbyContent)\n",
    "            handleLinebreaks(writtenbyContent, STR_SEPARATOR)\n",
    "            return str(writtenbyTag.div.string).strip()\n",
    "    return None\n",
    "\n",
    "def directedby(episodeInfobox:bs):\n",
    "    if episodeInfobox:\n",
    "        directedbyTag = episodeInfobox.find(attrs={\"data-source\": \"Directed By\"})\n",
    "        if directedbyTag:\n",
    "            directedbyContent =directedbyTag.div\n",
    "            handleP(directedbyContent)\n",
    "            handleLinks(directedbyContent)\n",
    "            handleLinebreaks(directedbyContent, STR_SEPARATOR)\n",
    "            return str(directedbyTag.div.string).strip()\n",
    "    return None\n",
    "\n",
    "def episodeAttrs(episodePage:bs, **moreAttributes):\n",
    "    infobox = episodePage.find(class_=\"portable-infobox\")\n",
    "    return {\n",
    "        **moreAttributes,\n",
    "        \"title\": episodePage.find(id=\"firstHeading\").string.strip(),\n",
    "        \"image_url\": image(infobox),\n",
    "        \"season\": season(episodePage),\n",
    "        \"episode_number_absolute\": episode_number(infobox),\n",
    "        \"production_code\": production_code(infobox),\n",
    "        \"airdate\": airdate(infobox),\n",
    "        \"main_characters\": maincharacters(infobox),\n",
    "        \"written_by\": writtenby(infobox),\n",
    "        \"directed_by\": directedby(infobox)\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODE_PAGE = \"https://simpsons.fandom.com/wiki/List_of_Episodes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def esepisodesPage(page:bs):\n",
    "    return page.find(id=\"firstHeading\").string.strip() == \"List of Episodes\"\n",
    "\n",
    "def episodesURLs(episodesPage:bs):\n",
    "    if not esepisodesPage(episodesPage):\n",
    "        raise ValueError(\"Soup received is not a episodes page\")\n",
    "    \n",
    "    episodes = episodesPage.find_all(\"td\", class_=\"oLeft\")\n",
    "    \n",
    "    links = []\n",
    "    for episode in episodes:\n",
    "        links.append(BASE_URL + episode.b.a[\"href\"])\n",
    "    return links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeEpisode(url:str):\n",
    "    if url in exceptions:\n",
    "        return None\n",
    "    episodePage = soup(url)\n",
    "    episode = episodeAttrs(episodePage, url=url)\n",
    "    return episode\n",
    "\n",
    "def scrapeEpisodesPage(url:str):\n",
    "    episodes = []\n",
    "    episodesPage = soup(url)\n",
    "\n",
    "    for episodeURL in episodesURLs(episodesPage):\n",
    "        episode = scrapeEpisode(episodeURL)\n",
    "        if episode:\n",
    "            episodes.append(episode)\n",
    "    return episodes\n",
    "\n",
    "def scrapeEpisodes(EpisodePage = EPISODE_PAGE):\n",
    "    episodes = []\n",
    "    episodesPageURL = EpisodePage\n",
    "    \n",
    "    pageEpisodes = scrapeEpisodesPage(episodesPageURL)\n",
    "    episodes.extend(pageEpisodes)\n",
    "\n",
    "    return episodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to write csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_FILE_NAME = \"episodes\"\n",
    "CSV_FILE_EXTENSION = \"csv\"\n",
    "\n",
    "def writeCsv(data:list[dict], filename = CSV_FILE_NAME):\n",
    "    if not data or len(data) <= 0:\n",
    "        return\n",
    "        \n",
    "    with open(filename+\".\"+CSV_FILE_EXTENSION, 'w', encoding='utf-8' , newline='') as f:\n",
    "        writer = csv.DictWriter(f,\n",
    "            fieldnames=data[0].keys(),\n",
    "            delimiter=';',\n",
    "            quotechar='\"',\n",
    "            escapechar=\"\\\\\",\n",
    "            quoting=csv.QUOTE_NONNUMERIC\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping a single episode (if we insert link in EPISODE_TEST_URL variable) or all episodes (otherwise). In the second case we have the time spent for scraping, the time for export and the total time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODE_TEST_URL = None # scrape only this if not None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if EPISODE_TEST_URL:\n",
    "        print(\"Testing single episode \" + EPISODE_TEST_URL)\n",
    "        pprint(scrapeEpisode(EPISODE_TEST_URL), sort_dicts=False)\n",
    "    else:\n",
    "        # Scrape\n",
    "        startScrapingTime = time.time()\n",
    "        episodes = scrapeEpisodes()\n",
    "        scrapingTime = time.time() - startScrapingTime\n",
    "        print(\"Scraping completed in \" + str(int(scrapingTime/60)) + \" min (\" + str(scrapingTime) + \" sec)\")\n",
    "        \n",
    "        # Export\n",
    "        startExportTime = time.time()\n",
    "        print(\"Now exporting to \" + CSV_FILE_NAME)\n",
    "        writeCsv(episodes)\n",
    "        exportTime = time.time() - startExportTime\n",
    "        print(\"Export completed in \" + str(int(exportTime/60)) + \" min (\" + str(exportTime) + \" sec)\")\n",
    "        \n",
    "        # Total\n",
    "        totalTime = time.time() - startScrapingTime\n",
    "        print(\"Number of episodes scraped: \" + str(len(episodes)))\n",
    "        print(\"Finished in \" + str(int(totalTime/60)) + \" min (\" + str(totalTime) + \" sec)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = pd.read_csv(\"C:\\GitHub\\Data-Management\\episodes.csv\", sep=\";\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deleting the episode without airdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes.drop(episodes.index[episodes[\"airdate\"] == \"TBA\"], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the number of NaN for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_url</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode_number_absolute</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>production_code</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airdate</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>main_characters</th>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>written_by</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>directed_by</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Total NaN\n",
       "url                              0\n",
       "title                            0\n",
       "image_url                        3\n",
       "season                         130\n",
       "episode_number_absolute          0\n",
       "production_code                  0\n",
       "airdate                          0\n",
       "main_characters                309\n",
       "written_by                       0\n",
       "directed_by                      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episodes_nan = pd.DataFrame(episodes.isna().sum(), columns=['Total NaN'])\n",
    "episodes_nan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculatin the percentage of NaN for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_nan['% NaN'] = (episodes_nan['Total NaN']/753)*100\n",
    "episodes_nan = episodes_nan.round(decimals=2)\n",
    "episodes_nan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completeness for Fandom Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m tot \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m episodes_nan:\n\u001b[1;32m----> 3\u001b[0m   tot \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m item\n\u001b[0;32m      4\u001b[0m completezza_tab \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m(tot \u001b[39m/\u001b[39m(episodes\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m*\u001b[39mepisodes\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])) \n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(completezza_tab)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "for item in episodes.isna().sum():\n",
    "  tot += item\n",
    "completezza_tab =1 -(tot /(episodes.shape[0]*episodes.shape[1])) \n",
    "print(completezza_tab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18b0eca292df7790ae02c99d513840323a4ed6febc80d490ebe22b975c5e1f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
