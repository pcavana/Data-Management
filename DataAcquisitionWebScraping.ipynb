{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Simpsons characters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scarping simpsons character from \"simpson.fandom.com\" with selenium, a python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('simpson_scraping_pagination.csv', 'w', encoding=\"utf-8\") as file:\n",
    "    file.write(\"full_name\" + \"\\n\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "driver.get(\"https://simpsons.fandom.com/wiki/Category:Characters?from=A\")\n",
    "\n",
    "# Maximize window\n",
    "driver.maximize_window()\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "# Accepts cookie (if it doesn't works try to change the first div[] with 7 or 6)\n",
    "cookie = driver.find_element(\"xpath\", \"/html/body/div[7]/div/div/div[2]/div[2]\")\n",
    "try:\n",
    "    cookie.click()\n",
    "except: \n",
    "    pass\n",
    "\n",
    "# In the moment there are 27 pages in the site\n",
    "count = 0\n",
    "for k in range(27) :\n",
    "    items = driver.find_elements(By.CLASS_NAME, \"category-page__member-link\")\n",
    "    \n",
    "    \n",
    "    with open('simpson_scraping_pagination.csv', 'a', encoding=\"utf-8\") as file:\n",
    "        for i in range(len(items)) :\n",
    "            file.write(items[i].text + \"\\n\")\n",
    "        \n",
    "        if (count==0) :\n",
    "            next = driver.find_element(\"xpath\", \"//*[@id=\\\"mw-content-text\\\"]/div[3]/a[2]\")\n",
    "            next.click()\n",
    "            count = count + 1\n",
    "        elif (count>=1) :\n",
    "            next = driver.find_element(\"xpath\", \"//*[@id=\\\"mw-content-text\\\"]/div[3]/a[3]\")\n",
    "            next.click()\n",
    "            count = count + 1\n",
    "\n",
    "            \n",
    "    file.close()\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column for lower case name of the characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_io.TextIOWrapper' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msimpson_scraping_pagination.csv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m----> 2\u001b[0m     file[\u001b[39m\"\u001b[39m\u001b[39mnormalized_name\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m file[\u001b[39m\"\u001b[39;49m\u001b[39mfull_name\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mlower()\n",
      "\u001b[1;31mTypeError\u001b[0m: '_io.TextIOWrapper' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "simpson_character = pd.read_csv(\"simpson_scraping_pagination.csv\", sep=\";\")\n",
    "\n",
    "simpson_character[\"normalized_name\"] = simpson_character[\"full_name\"].str.lower()\n",
    "\n",
    "simpson_character.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpson_character.to_csv(\"simpson_scraping.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18b0eca292df7790ae02c99d513840323a4ed6febc80d490ebe22b975c5e1f10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
